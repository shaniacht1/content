category: Analytics & SIEM
commonfields:
  id: Palo Alto Networks Cortex
  version: -1
configuration:
- defaultvalue: ""
  display: Authentication Token
  name: token
  required: true
  type: 4
- defaultvalue: ""
  display: Authentication ID
  name: auth_id
  required: true
  type: 4
- defaultvalue: ""
  display: Authentication Key
  name: auth_key
  required: true
  type: 4
- defaultvalue: "false"
  display: Use system proxy settings
  name: proxy
  required: false
  type: 8
- defaultvalue: "false"
  display: Trust any certificate (not secure)
  name: insecure
  required: false
  type: 8
- defaultvalue: ""
  display: Fetch incidents
  name: isFetch
  required: false
  type: 8
- defaultvalue: ""
  display: Incident type
  name: incidentType
  required: false
  type: 13
- defaultvalue: Traps Threats
  display: Query for fetching events
  name: fetch_query
  options:
  - Traps Threats
  - Firewall Threats
  - Cortex XDR Analytics
  required: false
  type: 15
- defaultvalue: 24 hours
  display: First fetch time (<number> <time unit>, e.g., 12 hours, 7 days, 3 months,
    1 year)
  name: first_fetch_timestamp
  required: false
  type: 0
- defaultvalue: ""
  display: Severity of events to fetch (Traps)
  name: traps_severity
  options:
  - all
  - critical
  - high
  - medium
  - low
  - informational
  - configuration
  required: false
  type: 16
- defaultvalue: ""
  display: Severity of events to fetch (Firewall)
  name: firewall_severity
  options:
  - all
  - critical
  - high
  - medium
  - low
  - informational
  - unused
  required: false
  type: 16
- defaultvalue: ""
  display: Subtype of events to fetch (Firewall)
  name: firewall_subtype
  options:
  - all
  - url
  - antivirus
  - spyware
  - vulnerability
  - file
  - scan
  - flood
  - packet
  - resource
  - data
  - wildfire
  - wildfire-virus
  required: false
  type: 16
- defaultvalue: ""
  display: Severity of alerts to fetch (XDR Analytics)
  name: xdr_severity
  options:
  - all
  - High
  - Medium
  - Low
  - Info
  required: false
  type: 16
- defaultvalue: ""
  display: Category of alerts to fetch (XDR Analytics)
  name: xdr_category
  options:
  - all
  - Consecutive Connections
  - DNS Tunneling
  - Failed Connections
  - Failed DNS
  - Grayware
  - High Connection Rate
  - Large Upload (FTP)
  - Large Upload (Generic)
  - Large Upload (HTTPS)
  - Large Upload (SMTP)
  - Malware
  - New Administrative Behavior
  - Port Scan
  - Random Looking DNS
  - Recurring Rare Domain Access
  - Recurring Rare IP Access
  - Remote Command Execution
  - Reverse Connection
  - SMB/KRB Traffic from Non-Standard Process
  - Script Connecting to Rare External Host
  - SpamBot Traffic
  - Tunneling Process
  - Uncommon ARP Cache Listing via arp.exe
  - Uncommon IP Configuration Listing via ipconfig.exe
  - Uncommon Local Scheduled Task Creation via schtasks.exe
  - Uncommon Net Group Execution
  - Uncommon Net User
  - Uncommon Remote Scheduled Task Creation via schtasks.exe
  - Uncommon Routing Table Listing via route.exe
  - Uncommon net localgroup Execution
  - scrons.exe Rare Child Process
  - wmiprsve.exe Rare Child Process
  - wsmprovhost.exe Rare Child Process
  required: false
  type: 16
description: This framework manages all PA's cloud managed products
detaileddescription: |
  There are several steps required to configure this integration. You will navigate between Demisto and [Cortex Hub](https://apps.paloaltonetworks.com/marketplace/demisto) to retrieve tokens required later in the process.

  For more information, see the [Palo Alto Networks Cortex](https://support.demisto.com/hc/en-us/articles/360004173094) integration documentation.
display: Palo Alto Networks Cortex
image: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHgAAAAyCAYAAACXpx/YAAAACXBIWXMAAAsSAAALEgHS3X78AAAD6klEQVR4nO2cS24bMQyGyaL75AbJCeo5QIH6BnVPkOkN3BPER8gN4tzA3XQbB+gBHHTbRbzq1kH3ZaGA4ygUNaPxxBOA4AcIqPWgHv9QosZOkYjAscs719Y2LrBxXGDjuMDGcYGN4wIbxwU2jgtsHBfYOC6wcVxg47jAxnGBjeMCG+f9W04PEacAENIDES2TCs7wNR77+2BEPAeABQBcRNl3RDRNKjuDGdWDEbEGgCsAOEkKnaPQW2BErHhbPY2ydwCwJqJN0uCluNdJQf/+Q79VUiAgonWS+WyjEuMvIRwjDwPs7OL14eMpJrGfm2+YGyLOAeAPAPwloh9Jb1HlogQAQaAwAGpJD5otfiC0dksuW/LnYH+u2SiwpaVg91SxsVbqdqXFQDtr0bYW5cFJKlEniLsR9eZc9hsA/gHAL22d9ja0TKWT4olkbMgHYxNPhs9kWZ4Ic4DAT7YUG28ucMm8owd/7xBR2UdOH7R1alLJFh06+STybnhyQbhz3kJmAHCmbDG1yH8MdbXtKGICACsWs4tvvDDNw1ixdzR9TsJ2KLbsJY8/5jL6951Snt3ymS3bzZHMl4gWHHQ2Aed+3ogoA9EbIqqjtj8z/SSdZBMvVvwEPQnaUn+m5MmnUPME+SQ3aarUlR5cUifpU2nTq77iwYmH9jj+5BrJneFg210ePBOf6zbPI6JVkpl64VVSI8+swHM0kgBGqfPanLPXSTrv+MEzOWCbcFa8Y94rOhTTK4pui0xbeLFtE9EuXzWhM1oODwwixjYrcQ175G3v2JyJbb7hrmPrbpjyUSOPs2nPNXtBL4FDyD6ksyMxaTE7eIFGRIthTnjHqw8dRte7aLkw86RGN9u4BgcVpWTv1RH37CVbkf+d44USG69BeBuHSuoMFDveEVxw+UF0CbxkL2i4DOcMX77jAZ6GQSCidtbJbb3PYEu21jkvYsViN3wecnaNBSLOhLhhvb+Idb8+WGQt8hIRnryQxxH1Wl7EC9vLC70WRa8y48lG0XxN2rX1lUuvEEUfcg+uxHj3LzuUMuIgNxlHW2otFCLJztSUaS9fdOyEMFLgdY8XHdPSRWtLYwusjDN5GBXnKJpLn2tS4+VLRFxxhzMlUt3yZHNRdmh3G30ObW8RsYkwm3M5bLFXHdeKHZ+58ed4rBt+zxtfxxYF23VsUztqNPqc77LuQuQtZbzA6w7iWAtHZF0aOI72dWFHIOFfFx6J0X7RwV75VQQPjhWB4Vnkit9lOyPwpn/h7z/ZOT7+XzgYx39VaRwX2DgusHFcYOO4wMZxgY3jAhvHBTaOC2wcF9g4LrBxXGDjuMDGcYEtAwD/AbjPSozwVJX9AAAAAElFTkSuQmCC
name: Palo Alto Networks Cortex
script:
  commands:
  - arguments:
    - defaultValue: 1970-01-01 00:00:00
      description: The query start time. For example, startTime="2018-04-26 00:00:00"
      name: startTime
    - default: true
      defaultValue: 2020-01-01 00:00:00
      description: The query end time. For example, endTime="2018-04-26 00:00:00"
      name: endTime
    - defaultValue: select * from panw.traffic limit 5
      description: 'A free-text SQL query. For example, query="select * from panw.traffic
        limit 5". There are multiple tables in Loggings, for example: threat, traffic,
        and so on. Refer to the Cortex Logging service schema reference for the full
        list.'
      name: query
    - auto: PREDEFINED
      description: The time range for the query, used with the rangeValue argument.
        For example, timeRange="weeks" timeValue="1" would run the query on the previous
        week.
      name: timeRange
      predefined:
      - minutes
      - days
      - weeks
    - description: The time value for the query, used with the timeRange argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: rangeValue
    description: Runs a query on the Cortex logging service.
    name: cortex-query-logs
    outputs:
    - contextPath: Cortex.Logging.id
      description: The ID of the log.
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log.
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log.
      type: Unknown
    - contextPath: Cortex.Logging.app
      description: The app of the log.
      type: Unknown
    - contextPath: Cortex.Logging.proto
      description: The protocol used.
      type: string
    - contextPath: Cortex.Logging.dst
      description: The destination IP.
      type: string
    - contextPath: Cortex.Logging.rule
      description: The rule used.
      type: Unknown
    - contextPath: Cortex.Logging.src
      description: The source of the action.
      type: Unknown
    - contextPath: Cortex.Logging.category-of-app
      description: The category of the application.
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: The source location.
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: The destination location.
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: The application's characteristics.
      type: Unknown
    - contextPath: Cortex.Logging.device_name
      description: The name of the device.
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used.
      type: number
    - contextPath: Cortex.Logging.natdport
      description: The NAT port.
      type: Unknown
    - contextPath: Cortex.Logging.natdst
      description: The NAT destination.
      type: Unknown
    - contextPath: Cortex.Logging.natsrc
      description: The NAT source.
      type: Unknown
  - arguments:
    - defaultValue: 1970-01-01 00:00:00
      description: The query start time. For example, startTime="2018-04-26 00:00:00"
      name: startTime
    - defaultValue: 2020-01-01 00:00:00
      description: The query end time. For example, endTime="2018-04-26 00:00:00"
      name: endTime
    - defaultValue: "10"
      description: The number of logs to return. Default is 10
      name: logsAmount
    - auto: PREDEFINED
      description: The time range for the query, used with the rangeValue argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: timeRange
      predefined:
      - minutes
      - days
      - weeks
    - description: The time value for the query, used with the timeRange argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: rangeValue
    description: Runs a query on the Cortex logging service, according to preset queries.
    name: cortex-get-critical-threat-logs
    outputs:
    - contextPath: Cortex.Logging.id
      description: The ID of the log.
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log.
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log.
      type: Unknown
    - contextPath: Cortex.Logging.app
      description: The app of the log.
      type: Unknown
    - contextPath: Cortex.Logging.proto
      description: The protocol used.
      type: string
    - contextPath: Cortex.Logging.dst
      description: The destination IP.
      type: string
    - contextPath: Cortex.Logging.rule
      description: The rule used.
      type: Unknown
    - contextPath: Cortex.Logging.src
      description: The source of the action.
      type: Unknown
    - contextPath: Cortex.Logging.category-of-app
      description: The category of the application.
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: The source location.
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: The destination location.
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: The application's characteristics.
      type: Unknown
    - contextPath: Cortex.Logging.device_name
      description: The name of the device.
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used.
      type: number
    - contextPath: Cortex.Logging.natdport
      description: The NAT port.
      type: Unknown
    - contextPath: Cortex.Logging.natdst
      description: The NAT destination.
      type: Unknown
    - contextPath: Cortex.Logging.natsrc
      description: The NAT source.
      type: Unknown
    - contextPath: Cortex.Logging.risk-of-app
      description: The risk of the application.
      type: Unknown
    - contextPath: Cortex.Logging.type
      description: The threat type.
      type: Unknown
    - contextPath: Cortex.Logging.pcad_id
      description: The PCAP ID.
      type: Unknown
    - contextPath: Cortex.Logging.reportid
      description: The report ID.
      type: number
    - contextPath: Cortex.Logging.category-of-threatid
      description: The category of the threat ID.
      type: Unknown
    - contextPath: Cortex.Logging.subtype
      description: The threat sub-type.
      type: Unknown
    - contextPath: Cortex.Logging.time_received
      description: The time the logging was received.
      type: Unknown
    - contextPath: Cortex.Logging.pcap
      description: The PCAP.
      type: Unknown
    - contextPath: Cortex.Logging.name-of-threatid
      description: The name of the threat ID.
      type: string
    - contextPath: Cortex.Logging.severity
      description: The threat severity.
      type: Unknown
  - arguments:
    - defaultValue: 1970-01-01 00:00:00
      description: Query start time. For example, startTime="2018-04-26 00:00:00"
      name: startTime
    - defaultValue: 2020-01-01 00:00:00
      description: Query end time. For example, endTime="2018-04-26 00:00:00"
      name: endTime
    - defaultValue: "10"
      description: Amount of logs. Default is 10
      name: logsAmount
    - auto: PREDEFINED
      description: The time range for the query, used with the rangeValue argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: timeRange
      predefined:
      - minutes
      - days
      - weeks
    - description: The time value for the query, used with the timeRange argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: rangeValue
    description: Runs a query on the Cortex logging service, according to preset queries.
    name: cortex-get-social-applications
    outputs:
    - contextPath: Cortex.Logging.id
      description: The id of the log.
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log.
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log.
      type: Unknown
    - contextPath: Cortex.Logging.app
      description: The app of the log.
      type: Unknown
    - contextPath: Cortex.Logging.proto
      description: The protocol used.
      type: string
    - contextPath: Cortex.Logging.dst
      description: The destination IP.
      type: string
    - contextPath: Cortex.Logging.rule
      description: The rule used.
      type: Unknown
    - contextPath: Cortex.Logging.src
      description: The source of the action.
      type: Unknown
    - contextPath: Cortex.Logging.category-of-app
      description: The category of the application.
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: The source location.
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: The destination location.
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: The application's characteristics.
      type: Unknown
    - contextPath: Cortex.Logging.device_name
      description: The name of the device.
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used.
      type: number
    - contextPath: Cortex.Logging.natdport
      description: The NAT port.
      type: Unknown
    - contextPath: Cortex.Logging.natdst
      description: The NAT destination.
      type: Unknown
    - contextPath: Cortex.Logging.natsrc
      description: The NAT source.
      type: Unknown
    - contextPath: Cortex.Logging.risk-of-app
      description: The risk of the application.
      type: Unknown
    - contextPath: Cortex.Logging.aggregations.size
      description: The aggregations size.
      type: Unknown
    - contextPath: Cortex.Logging.natsport
      description: The NAT port.
      type: Unknown
    - contextPath: Cortex.Logging.start
      description: The traffic start.
      type: Unknown
    - contextPath: Cortex.Logging.subcategory-of-apptime_received
      description: The sub-category of the application time.
      type: Unknown
  - arguments:
    - defaultValue: 1970-01-01 00:00:00
      description: The query start time. For example, startTime="2018-04-26 00:00:00"
      name: startTime
    - defaultValue: 2020-01-01 00:00:00
      description: The query end time. For example, endTime="2018-04-26 00:00:00"
      name: endTime
    - defaultValue: "10"
      description: The number of logs to return. Default is 10.
      name: logsAmount
    - auto: PREDEFINED
      description: The time range for the query, used with the rangeValue argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the previous
        week.
      name: timeRange
      predefined:
      - minutes
      - days
      - weeks
    - description: The time value for the query, used with the timeRange argument.
        For example, timeRange="weeks" rangeValue="1" would run the query on the last
        week.
      name: rangeValue
    - description: The SHA256 hash of the file for the query. For example, SHA256="503ca1a4fc0d48b18c0336f544ba0f0abf305ae3a3f49b3c2b86b8645d6572dc"
        would return all logs associated with this file.
      name: SHA256
      required: true
    description: Runs a query on the Cortex logging service, according to preset queries.
    name: cortex-search-by-file-hash
    outputs:
    - contextPath: Cortex.Logging.id
      description: The ID of the log.
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log.
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log.
      type: Unknown
    - contextPath: Cortex.Logging.app
      description: The app of the log.
      type: Unknown
    - contextPath: Cortex.Logging.proto
      description: The protocol used.
      type: string
    - contextPath: Cortex.Logging.dst
      description: The destination IP address.
      type: string
    - contextPath: Cortex.Logging.rule
      description: The rule used.
      type: Unknown
    - contextPath: Cortex.Logging.src
      description: The source of the action.
      type: Unknown
    - contextPath: Cortex.Logging.category-of-app
      description: The category of the application.
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: The source location.
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: The destination location.
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: The application's characteristics.
      type: Unknown
    - contextPath: Cortex.Logging.device_name
      description: The name of the device.
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used.
      type: number
    - contextPath: Cortex.Logging.natdport
      description: The NAT port.
      type: Unknown
    - contextPath: Cortex.Logging.natdst
      description: The NAT destination.
      type: Unknown
    - contextPath: Cortex.Logging.natsrc
      description: The NAT source.
      type: Unknown
    - contextPath: Cortex.Logging.risk-of-app
      description: The risk of the application.
      type: Unknown
    - contextPath: Cortex.Logging.type
      description: The threat type.
      type: Unknown
    - contextPath: Cortex.Logging.pcad_id
      description: The PCAP ID.
      type: Unknown
    - contextPath: Cortex.Logging.reportid
      description: The report ID.
      type: number
    - contextPath: Cortex.Logging.category-of-threatid
      description: The category of the threat ID.
      type: Unknown
    - contextPath: Cortex.Logging.subtype
      description: The threat sub-type.
      type: Unknown
    - contextPath: Cortex.Logging.time_received
      description: The time the logging was received.
      type: Unknown
    - contextPath: Cortex.Logging.pcap
      description: The PCAP.
      type: Unknown
    - contextPath: Cortex.Logging.name-of-threatid
      description: The name of the threat ID.
      type: string
    - contextPath: Cortex.Logging.severity
      description: Threat Severity.
      type: Unknown
  dockerimage: demisto/python_pancloud:1.0.0.286
  isfetch: true
  runonce: false
  script: |2-



    ''' IMPORTS '''
    import os
    import requests
    import json
    from pancloud import LoggingService, Credentials
    import base64
    from cryptography.hazmat.primitives.ciphers.aead import AESGCM

    # disable insecure warnings
    requests.packages.urllib3.disable_warnings()

    ''' GLOBAL VARS '''
    AUTH_ID = demisto.params().get('auth_id')
    # If there's a stored token in integration context, it's newer than current
    TOKEN = demisto.getIntegrationContext().get('token')
    if not TOKEN:
        TOKEN = demisto.params().get('token')

    ENC_KEY = demisto.params().get('auth_key')

    USE_SSL = not demisto.params().get('insecure', False)
    TOKEN_RETRIEVAL_URL = 'https://demistobot.demisto.com/panw-token'
    FETCH_QUERY = None

    FIRST_FETCH_TIMESTAMP = demisto.params().get('first_fetch_timestamp', '').strip()
    if not FIRST_FETCH_TIMESTAMP:
        FIRST_FETCH_TIMESTAMP = '24 hours'

    if not demisto.params().get('proxy', False):
        os.environ.pop('HTTP_PROXY', '')
        os.environ.pop('HTTPS_PROXY', '')
        os.environ.pop('http_proxy', '')
        os.environ.pop('https_proxy', '')

    FETCH_QUERY_DICT = {
        'Traps Threats': 'SELECT * FROM tms.threat',
        'Firewall Threats': 'SELECT * FROM panw.threat',
        'Cortex XDR Analytics': 'SELECT * FROM magnifier.alert'
    }

    THREAT_TABLE_HEADERS = [
        'id', 'score', 'risk-of-app', 'type', 'action', 'app', 'pcap_id', 'proto', 'dst', 'reportid',
        'rule', 'category-of-threatid', 'characteristic-of-app', 'device_name', 'subtype',
        'time_received', 'pcap', 'name-of-threatid', 'severity', 'nat', 'natdport', 'natdst',
        'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc', 'category', 'SHA256', 'filetype', 'filename'
    ]

    TRAFFIC_TABLE_HEADERS = [
        'id', 'score', 'aggregations.size', 'action', 'app', 'proto', 'dst', 'rule', 'characteristic-of-app',
        'device_name', 'risk-of-app', 'natsport', 'start', 'subcategory-of-app', 'time_received',
        'nat', 'natdport', 'natdst', 'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc'
    ]

    COMMON_HEADERS = [
        'id', 'score', 'action', 'app', 'proto', 'dst', 'rule', 'characteristic-of-app', 'device_name',
        'nat', 'natdport', 'natdst', 'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc', 'filetype',
        'SHA256', 'filename'
    ]

    ''' HELPER FUNCTIONS '''


    def get_encrypted(auth_id: str, key: str) -> str:
        """

        Args:
            auth_id (str): auth_id from Demistobot
            key (str): key from Demistobot

        Returns:

        """
        def create_nonce() -> bytes:
            return os.urandom(12)

        def encrypt(string: str, enc_key: str) -> bytes:
            """

            Args:
                enc_key (str):
                string (str):

            Returns:
                bytes:
            """
            # String to bytes
            enc_key = enc_key.encode()
            # Create key
            aes_gcm = AESGCM(enc_key)
            # Create nonce
            nonce = create_nonce()
            # Create ciphered data
            data = string.encode()
            ct = aes_gcm.encrypt(nonce, data, None)
            return base64.b64encode(nonce + ct)
        now = epoch_seconds()
        return encrypt(f'{now}:{auth_id}', key).decode('utf-8')


    def prepare_fetch_query(fetch_timestamp):
        query = FETCH_QUERY_DICT[demisto.params().get('fetch_query', 'Traps Threats')]
        if 'tms' in query:
            query += f" WHERE serverTime>'{fetch_timestamp}'"
            FETCH_SEVERITY = demisto.params().get('traps_severity')
            if not FETCH_SEVERITY:
                FETCH_SEVERITY = ['all']
            if 'all' not in FETCH_SEVERITY:
                query += ' AND ('
                for index, severity in enumerate(FETCH_SEVERITY):
                    if index == (len(FETCH_SEVERITY) - 1):
                        query += f"messageData.trapsSeverity='{severity}'"
                    else:
                        query += f"messageData.trapsSeverity='{severity}' OR "
                query += ')'
        if 'panw' in query:
            query += f' WHERE receive_time>{fetch_timestamp}'
            FETCH_SEVERITY = demisto.params().get('firewall_severity')
            if not FETCH_SEVERITY:
                FETCH_SEVERITY = ['all']
            FETCH_SUBTYPE = demisto.params().get('firewall_subtype')
            if not FETCH_SUBTYPE:
                FETCH_SUBTYPE = ['all']
            if 'all' not in FETCH_SUBTYPE:
                query += ' AND ('
                for index, subtype in enumerate(FETCH_SUBTYPE):
                    if index == (len(FETCH_SUBTYPE) - 1):
                        query += f"subtype='{subtype}'"
                    else:
                        query += f"subtype='{subtype}' OR "
                query += ')'
            if 'all' not in FETCH_SEVERITY:
                query += ' AND ('
                for index, severity in enumerate(FETCH_SEVERITY):
                    if index == (len(FETCH_SEVERITY) - 1):
                        query += f"severity='{severity}'"
                    else:
                        query += f"severity='{severity}' OR "
                query += ')'
        if 'magnifier' in query:
            query += f' WHERE time_generated>{fetch_timestamp}'
            FETCH_SEVERITY = demisto.params().get('xdr_severity')
            if not FETCH_SEVERITY:
                FETCH_SEVERITY = ['all']
            FETCH_CATEGORY = demisto.params().get('xdr_category')
            if not FETCH_CATEGORY:
                FETCH_CATEGORY = ['all']
            if 'all' not in FETCH_CATEGORY:
                query += ' AND ('
                for index, subtype in enumerate(FETCH_CATEGORY):
                    if index == (len(FETCH_CATEGORY) - 1):
                        query += f"alert.category.keyword='{subtype}'"
                    else:
                        query += f"alert.category.keyword='{subtype}' OR "
                query += ')'
            if 'all' not in FETCH_SEVERITY:
                query += ' AND ('
                for index, severity in enumerate(FETCH_SEVERITY):
                    if index == (len(FETCH_SEVERITY) - 1):
                        query += f"alert.severity.keyword='{severity}'"
                    else:
                        query += f"alert.severity.keyword='{severity}' OR "
                query += ')'
            # Only get new Alerts
            query += ' AND sub_type.keyword = \'New\''
        return query


    def epoch_seconds(d=None):
        """
        Return the number of seconds for given date. If no date, return current.

        parameter: (date) d
            The date to convert to seconds

        returns:
            The date in seconds
        """
        if not d:
            d = datetime.utcnow()
        return int((d - datetime.utcfromtimestamp(0)).total_seconds())


    def get_access_token():
        integration_context = demisto.getIntegrationContext()
        access_token = integration_context.get('access_token')
        stored = integration_context.get('stored')
        if access_token and stored:
            if epoch_seconds() - stored < 60 * 60 - 30:
                return access_token
        headers = {
            'Authorization': AUTH_ID,
            'Accept': 'application/json'
        }

        dbot_response = requests.get(
            TOKEN_RETRIEVAL_URL,
            headers=headers,
            params={'token': get_encrypted(TOKEN, ENC_KEY)},
            verify=USE_SSL
        )
        if dbot_response.status_code not in {200, 201}:
            msg = 'Error in authentication. Try checking the credentials you entered.'
            try:
                demisto.info('Authentication failure from server: {} {} {}'.format(
                    dbot_response.status_code, dbot_response.reason, dbot_response.text))
                err_response = dbot_response.json()
                server_msg = err_response.get('message')
                if not server_msg:
                    title = err_response.get('title')
                    detail = err_response.get('detail')
                    if title:
                        server_msg = f'{title}. {detail}'
                if server_msg:
                    msg += ' Server message: {}'.format(server_msg)
            except Exception as ex:
                demisto.error('Failed parsing error response: [{}]. Exception: {}'.format(err_response.content, ex))
            raise Exception(msg)
        try:
            parsed_response = dbot_response.json()
        except ValueError:
            raise Exception(
                'There was a problem in retrieving an updated access token.\n'
                'The response from the Demistobot server did not contain the expected content.'
            )
        access_token = parsed_response.get('access_token')
        api_url = parsed_response.get('url')
        token = parsed_response.get('token')

        demisto.setIntegrationContext({
            'access_token': access_token,
            'stored': epoch_seconds(),
            'api_url': api_url,
            'token': token
        })
        return access_token


    def initial_logging_service():
        api_url = demisto.getIntegrationContext().get('api_url', 'https://api.us.paloaltonetworks.com')
        credentials = Credentials(
            access_token=get_access_token(),
            verify=USE_SSL
        )
        logging_service = LoggingService(
            url=api_url,
            credentials=credentials
        )

        return logging_service


    def poll_query_result(query_id):

        logging_service = initial_logging_service()

        poll_params = {  # Prepare 'poll' params
            "maxWaitTime": 30000  # waiting for response up to 3000ms
        }

        # we poll the logging service until we have a complete response
        response = logging_service.poll(query_id, 0, poll_params)

        return response


    def query_loggings(query_data):
        """
        This function handles all the querying of Cortex Logging service
        """

        logging_service = initial_logging_service()

        response = logging_service.query(query_data)
        query_result = response.json()

        if not response.ok:
            status_code = query_result.get('statusCode', '')
            error = query_result.get('error', '')
            message = query_result.get('payload', {}).get('message', '')
            raise Exception(f"Error in query to Cortex [{status_code}] - {error}: {message}")

        try:
            query_id = query_result['queryId']  # access 'queryId' from 'query' response
        except Exception as e:
            raise Exception('Received error %s when querying logs.' % e)

        poll_response = poll_query_result(query_id)
        return poll_response


    def transform_row_keys(row):
        transformed_row = {}
        for metric, value in row.items():
            if metric == 'filedigest':
                transformed_row['SHA256'] = value
            elif metric == 'misc':
                transformed_row['filename'] = value
            elif metric == 'category' and str(value) == '1':
                transformed_row['category'] = 'malicious'
            else:
                transformed_row[metric] = value
        return transformed_row


    def results_screener(table_name, full_results):
        """
        This function is used to make sure we include only pre-defined metrics in the human readable
        """
        screened_results = []

        if table_name == "traffic":
            for row in full_results:
                screened_row = {metric: value for metric, value in row.items() if metric in TRAFFIC_TABLE_HEADERS}
                screened_results.append(screened_row)
        elif table_name == "threat":
            for row in full_results:
                screened_row = {metric: value for metric, value in row.items() if metric in THREAT_TABLE_HEADERS}
                screened_results.append(screened_row)
        elif table_name == "common":
            for row in full_results:
                screened_row = {metric: value for metric, value in row.items() if metric in COMMON_HEADERS}
                screened_results.append(screened_row)
        else:
            return full_results

        return screened_results


    def get_start_time(date_type, time_value):
        current_date = datetime.now()
        if date_type == 'minutes':
            return current_date - timedelta(minutes=time_value)
        elif date_type == 'days':
            return current_date - timedelta(days=time_value)
        elif date_type == 'weeks':
            return current_date - timedelta(weeks=time_value)


    def convert_log_to_incident(log):
        log_contents = log.get('_source')
        if log_contents.get('id'):
            log_contents['xdr_id'] = log_contents.get('id')  # XDR ID before it is overwritten
        log_contents['id'] = log.get('_id')
        log_contents['score'] = log.get('_score')
        if 'Traps' in FETCH_QUERY:  # type: ignore
            occurred = log_contents.get('generatedTime')
            time_received = log_contents.get('serverTime')
        elif 'Firewall' in FETCH_QUERY:  # type: ignore
            time_generated = log_contents.get('time_generated')
            occurred = datetime.utcfromtimestamp(time_generated).isoformat() + 'Z'
            time_received = log_contents.get('receive_time')
        elif 'XDR' in FETCH_QUERY:  # type: ignore
            # first_detected_at in alert.schedule can be present or not, can be in s or ms
            # if not detected, fallback to time_generated
            try:
                time_received = int(log_contents.get('time_generated')) or 0
            except ValueError:
                time_received = 0

            occurred_raw = 0
            first_detected_at = None
            try:
                first_detected_at = str(log_contents.get('alert', {}).get('schedule', {}).get('first_detected_at'))
            except AttributeError:
                first_detected_at = None
            if first_detected_at is not None:
                if len(first_detected_at) == 13:  # ms
                    occurred_raw = int(float(first_detected_at) / 1000)
                elif len(first_detected_at) == 10:  # s
                    occurred_raw = int(first_detected_at)
                else:  # unknown length, fallback to time_received
                    occurred_raw = int(time_received)
            else:  # not present, fallback to time_received
                occurred_raw = int(time_received)
            occurred = datetime.utcfromtimestamp(occurred_raw).isoformat() + 'Z'

        # stringifying dictionary values for fetching. (json.dumps() doesn't stringify dictionary values)
        event_id = log.get('_id', '')
        incident = {
            'name': 'Cortex Event ' + event_id,
            'rawJSON': json.dumps(log_contents, ensure_ascii=False),
            'occurred': occurred
        }
        return incident, time_received


    ''' COMMANDS FUNCTIONS '''


    def query_logs_command():
        """
        Return the result of querying the Logging service
        """
        args = demisto.args()
        start_time = args.get('startTime')
        end_time = args.get('endTime')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if time_range:
            if time_value:
                service_end_date = datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise Exception('Enter timeRange and timeValue, or startTime and endTime')
        else:
            time_format = '%Y-%m-%d %H:%M:%S'
            # Thu Jan 01 02:00:00 IST 1970' does not match format '%Y-%m-%d %H:%M:%S'
            service_start_date = datetime.strptime(start_time, time_format)
            service_end_date = datetime.strptime(end_time, time_format)

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime('%s'))
        service_end_date_epoch = int(service_end_date.strftime('%s'))

        query = args.get('query')

        if 'limit' not in query.lower():
            query += ' LIMIT 100'

        query_data = {
            "query": query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        response = query_loggings(query_data)

        try:
            response_json = response.json()
            query_status = response_json.get('queryStatus', '')
            if query_status in {'RUNNING', 'JOB_FAILED'}:
                raise Exception(f'Logging query job failed with status: {query_status}')
            result = response_json.get('result', {})
            pages = result.get('esResult', {}).get('hits', {}).get('hits', [])
            table_name = result['esQuery']['table'][0].split('.')[1]
        except ValueError:
            raise Exception('Failed to parse the response from Cortex')

        output = []

        for page in pages:
            row_contents = page.get('_source')
            row_contents['id'] = page.get('_id')
            row_contents['score'] = page.get('_score')
            transformed_row = transform_row_keys(row_contents)
            output.append(transformed_row)

        screened_results = results_screener('common', output)

        entry = {
            'Type': entryTypes['note'],
            'Contents': output,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table', screened_results),
            'EntryContext': {
                'Cortex.Logging(val.id===obj.id)': output
            }
        }

        return entry


    def get_critical_logs_command():
        """
        Queries Cortex Logging according to a pre-set query
        """

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if time_range:
            if time_value:
                service_end_date = datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise Exception('Enter timeRange and timeValue, or startTime and endTime')
        else:
            # parses user input to datetime object
            service_start_date = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.threat WHERE severity = '5' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        response = query_loggings(query_data)

        try:
            result = response.json()['result']
            pages = result.get('esResult', {}).get('hits', {}).get('hits', [])
            table_name = result['esQuery']['table'][0].split('.')[1]
        except ValueError:
            raise Exception('Failed to parse the response from Cortex')

        output = []

        for page in pages:
            row_contents = page.get('_source')
            row_contents['id'] = page.get('_id')
            row_contents['score'] = page.get('_score')
            transformed_row = transform_row_keys(row_contents)
            output.append(transformed_row)

        screened_results = results_screener('threat', output)

        entry = {
            'Type': entryTypes['note'],
            'Contents': output,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table', screened_results),
            'EntryContext': {
                'Cortex.Logging(val.id==obj.id)': output
            }
        }
        return entry


    def get_social_applications_command():
        """ Queries Cortex Logging according to a pre-set query """

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if time_range:
            if time_value:
                service_end_date = datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise Exception('Enter timeRange and timeValue, or startTime and endTime')
        else:
            # parses user input to datetime object
            service_start_date = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.traffic WHERE subcategory-of-app = 'social-networking' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        response = query_loggings(query_data)

        try:
            result = response.json()['result']
            pages = result.get('esResult', {}).get('hits', {}).get('hits', [])
            table_name = result['esQuery']['table'][0].split('.')[1]
        except ValueError:
            raise Exception('Failed to parse the response from Cortex')

        output = []

        for page in pages:
            row_contents = page.get('_source')
            row_contents['id'] = page.get('_id')
            row_contents['score'] = page.get('_score')
            transformed_row = transform_row_keys(row_contents)
            output.append(transformed_row)

        screened_results = results_screener('traffic', output)

        entry = {
            'Type': entryTypes['note'],
            'Contents': output,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table', screened_results),
            'EntryContext': {
                'Cortex.Logging(val.id===obj.id)': output
            }
        }
        return entry


    def search_by_file_hash_command():
        """
        Queries Cortex Logging according to a pre-set query
        """

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')
        filehash = args.get('SHA256')

        if (time_range):
            if (time_value):
                service_end_date = datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise Exception('Please enter timeRange and timeValue, or startTime and endTime')
        else:
            # parses user input to datetime object
            service_start_date = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.threat WHERE filedigest='" + filehash + "' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        response = query_loggings(query_data)

        try:
            result = response.json()['result']
            pages = result.get('esResult', {}).get('hits', {}).get('hits', [])
            table_name = result['esQuery']['table'][0].split('.')[1]
        except ValueError:
            raise Exception('Failed to parse the response from Cortex')

        output = []

        for page in pages:
            row_contents = page.get('_source')
            row_contents['id'] = page.get('_id')
            row_contents['score'] = page.get('_score')
            transformed_row = transform_row_keys(row_contents)
            output.append(transformed_row)

        screened_results = results_screener('threat', output)

        entry = {
            'Type': entryTypes['note'],
            'Contents': output,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table', screened_results),
            'EntryContext': {
                'Cortex.Logging(val.id==obj.id)': output
            }
        }
        return entry


    def process_incident_pairs(incident_pairs, max_incidents):
        sorted_pairs = sorted(incident_pairs, key=lambda x: x[1])
        sorted_pairs = sorted_pairs[:max_incidents]
        max_timestamp = sorted_pairs[-1][1]
        return list(map(lambda x: x[0], sorted_pairs)), max_timestamp


    def fetch_incidents():

        last_run = demisto.getLastRun()
        last_fetched_event_timestamp = last_run.get('last_fetched_event_timestamp')
        last_query_id = last_run.get('last_query_id')

        if last_query_id:
            # Need to poll query results fron last run
            response = poll_query_result(last_query_id)
        else:
            if last_fetched_event_timestamp is not None:
                last_fetched_event_timestamp = datetime.strptime(last_fetched_event_timestamp, '%Y-%m-%dT%H:%M:%S.%f')
            else:
                last_fetched_event_timestamp, _ = parse_date_range(FIRST_FETCH_TIMESTAMP)

            # Need sometime in the future, so the timestamp will be taken from the query
            service_end_date_epoch = int(datetime.now().strftime('%s')) + 1000

            if 'Firewall' in FETCH_QUERY or 'XDR' in FETCH_QUERY:  # type: ignore
                fetch_timestamp = int(last_fetched_event_timestamp.strftime('%s'))
            elif 'Traps' in FETCH_QUERY:  # type: ignore
                fetch_timestamp = last_fetched_event_timestamp.strftime('%Y-%m-%dT%H:%M:%S.%fZ')

            query = prepare_fetch_query(fetch_timestamp)

            query_data = {
                'query': query,
                'startTime': 0,
                'endTime': service_end_date_epoch,
            }

            response = query_loggings(query_data)

        try:
            response_json = response.json()
            query_status = response_json.get('queryStatus', '')
            if query_status == 'JOB_FAILED':
                raise Exception(f'Logging query job failed with status: JOB_FAILED\nResponse: {response.text}')
            elif query_status == 'RUNNING':
                if isinstance(last_fetched_event_timestamp, datetime):
                    # In case we don't have query ID from previous run
                    last_fetched_event_timestamp = last_fetched_event_timestamp.strftime('%Y-%m-%dT%H:%M:%S.%f')
                # If query job is still running after 30 seconds (max timeout), pass it to next run
                demisto.setLastRun({
                    'last_fetched_event_timestamp': last_fetched_event_timestamp,
                    'last_query_id': response_json.get('queryId', '')
                })
                demisto.incidents([])
                return
            result = response_json.get('result', {})
            pages = result.get('esResult', {}).get('hits', {}).get('hits', [])
        except ValueError:
            raise Exception('Failed to parse the response from Cortex')

        incident_pairs = []

        max_fetched_event_timestamp = last_fetched_event_timestamp
        for page in pages:
            incident, time_received = convert_log_to_incident(page)
            if 'Firewall' in FETCH_QUERY or 'XDR' in FETCH_QUERY:  # type: ignore
                time_received_dt = datetime.fromtimestamp(time_received)
            elif 'Traps' in FETCH_QUERY:  # type: ignore
                time_received_dt = datetime.strptime(time_received, '%Y-%m-%dT%H:%M:%S.%fZ')
            incident_pairs.append((incident, time_received_dt))
        if incident_pairs:
            incidents, max_fetched_event_timestamp = process_incident_pairs(incident_pairs, 100)  # max 100 per run
            demisto.setLastRun({
                'last_fetched_event_timestamp': max_fetched_event_timestamp.strftime('%Y-%m-%dT%H:%M:%S.%f')
            })
            demisto.incidents(incidents)
        else:
            demisto.incidents([])


    ''' EXECUTION CODE '''


    def main():
        global FETCH_QUERY
        FETCH_QUERY = demisto.params().get('fetch_query', 'Traps Threats')

        LOG('command is %s' % (demisto.command(),))
        try:
            if demisto.command() == 'test-module':
                if demisto.params().get('isFetch'):
                    last_fetched_event_timestamp, _ = parse_date_range(FIRST_FETCH_TIMESTAMP)
                test_args = {
                    "query": "SELECT * FROM panw.threat LIMIT 1",
                    "startTime": 0,
                    "endTime": 1609459200,
                }
                if query_loggings(test_args):
                    demisto.results('ok')
                else:
                    demisto.results('test failed')
            elif demisto.command() == 'cortex-query-logs':
                demisto.results(query_logs_command())
            elif demisto.command() == 'cortex-get-critical-threat-logs':
                demisto.results(get_critical_logs_command())
            elif demisto.command() == 'cortex-get-social-applications':
                demisto.results(get_social_applications_command())
            elif demisto.command() == 'cortex-search-by-file-hash':
                demisto.results(search_by_file_hash_command())
            elif demisto.command() == 'fetch-incidents':
                fetch_incidents()
        except Exception as e:
            error_message = str(e)
            if demisto.command() == 'fetch-incidents':
                LOG(error_message)
                LOG.print_log()
                raise
            else:
                return_error(error_message)


    # python2 uses __builtin__ python3 uses builtins
    if __name__ == "__builtin__" or __name__ == "builtins":
        main()
  subtype: python3
  type: python
system: true
